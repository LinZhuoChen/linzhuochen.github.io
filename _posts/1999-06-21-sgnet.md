---
layout: project
title: SGNet
permalink: /sgnet/
---

<style>
#jittor-home-head {
  background: url(assets/images/bg1.jpg) no-repeat center;
  height:400px;
}

.view-more {
  background-color: transparent;
  border-color: #46a1b4;
  border-radius: 0px;
  color: #46a1b4;
  font-size:14px;
  margin-top: 20px;
}

.hservice {
  /*background: rgb(242, 247, 255);*/
  background-color: rgba(185, 208, 240, 0.16);
  border: 1px solid #CED8E7;
  transition: all 0.3s ease-in;
  margin-right: 200px;
  overflow: hidden;
  height: 400px;
}
.hservice:hover 
{
  box-shadow: 0px 2px 3px 2px #CED8E7;
}

.hservice:hover .service-img 
{
  opacity: 1;
}
</style>

<p align="center">
<br />
  <h3 align="center">Spatial information guided Convolution for Real-Time 
  RGBD Semantic Segmentation</h3>
  <p align="center">
    Lin-Zhuo Chen, Zheng Lin, Ziqin Wang, Yong-Liang Yang and Ming-Ming Cheng
    <br />
    <a href="https://mmcheng.net/sgnet/"><strong>‚≠ê Project Home ¬ª</strong></a>
    <br />
    <a href="https://arxiv.org/pdf/2004.04534.pdf" target="_black">[PDF <i class="fas fa-book"></i>]</a>
    <a href="https://github.com/LinZhuoChen/SGNet" target="_black">[Code <i class="fab fa-github"></i>]</a>
    <br />
    <br /> 
  </p>
</p>

<style type="text/css">
img{text-align: center; margin: 0 auto;}
</style>

### Abstract
<body>
    <p style="text-align:justify; text-justify:inter-ideograph">
        3D spatial information is known to be beneficial to the semantic segmentation task. Most existing methods take 3D spatial data as an additional input, leading to a two-stream segmentation network that processes RGB and 3D spatial information separately. This solution greatly increases the inference time and severely limits its scope for real-time applications. To solve this problem, we propose Spatial information guided Convolution (S-Conv), which allows efficient RGB feature and 3D spatial information integration. S-Conv is competent to infer the sampling offset of the convolution kernel guided by the 3D spatial information, helping the convolutional layer adjust the receptive field and adapt to geometric transformations. S-Conv also incorporates geometric information into the feature learning process by generating spatially adaptive convolutional weights. The capability of perceiving geometry is largely enhanced without much affecting the amount of parameters and computational cost. We further embed S-Conv into a semantic segmentation network, called Spatial information Guided convolutional Network (SGNet), resulting in real-time inference and state-of-the-art performance on NYUDv2 and SUNRGBD datasets.
</p>
</body>

### Architecture of S-Conv

<div style="text-align:center" markdown="1">
![Architecture of S-Conv](/images/s_conv2.png "Architecture of S-Conv")
</div>


### Results
Following results tested under NVIDIA 1080TI GPU, Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz:

**Results on NYUDv2 Dataset**

<div style="text-align:center" markdown="1">
![Results](/images/sgnet_result.png "Results")
</div>

<div style="text-align:center" markdown="1">
![Results](/images/sconv_compare.png "Results")
</div>

|    Model     | mIoU(480x640) | mIoU(MS) | FPS(480x640) | FPS(425x560) |
| :----------: | :-----------: | :------: | :----------: | :----------: |
| SGNet(Res50) |     47.7%     |  48.6%   |      35      |      39      |
|    SGNet     |     49.6%     |  51.1%   |      26      |      28      |
|  SGNet_ASPP  |     50.2%     |  51.1%   |      24      |      26      |

**Results on SUNRGBD Dataset**

|   Model    | mIoU(480x640) | mIoU(MS) | FPS(480x640) | FPS(425x560) |
| :--------: | :-----------: | :------: | :----------: | :----------: |
|   SGNet    |     47.1%     |  48.5%   |      26      |      28      |
| SGNet_ASPP |     47.5%     |  48.6%   |      24      |      26      |



### **Some follow-up work**

**Global-Local Propagation Network for RGB-D Semantic Segmentation.** 
Chen Sihan, Xinxin Zhu, Wei Liu, Xingjian He, and Jing Liu. 
arXiv preprint arXiv:2101.10801 (2021).


**Modality-Guided Subnetwork for Salient Object Detection.** 
Wu, Zongwei, Guillaume Allibert, Christophe Stolz, Chao Ma, and C√©dric Demonceaux. 
arXiv preprint arXiv:2110.04904 (2021).


### **Paper**

**Spatial Information Guided Convolution for Real-Time RGBD Semantic Segmentation.** 
Lin-Zhuo Chen, Zheng Lin, Ziqin Wang, Yong-Liang Yang, Ming-Ming Cheng*. 
IEEE TIP, 2021. 

**If you find our work is helpful, please cite**
```bash
@article{21TIP-SGNet,   
  author={Lin-Zhuo Chen and Zheng Lin and Ziqin Wang and Yong-Liang Yang and Ming-Ming Cheng},   
  journal={IEEE Transactions on Image Processing},    
  title={Spatial Information Guided Convolution for Real-Time RGBD Semantic Segmentation}, 
  year={2021},   
  volume={30},
  pages={2313-2324},  
  doi={10.1109/TIP.2021.3049332} 
}
```

If you have any questions, feel free to contact me via `linzhuochenü•≥foxmailüò≤com`